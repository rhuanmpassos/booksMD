# ðŸš€ Guia de Deploy na Vercel - BooksMD

## ðŸ“‹ Ãndice
1. [AnÃ¡lise do Projeto](#anÃ¡lise-do-projeto)
2. [LimitaÃ§Ãµes e Desafios](#limitaÃ§Ãµes-e-desafios)
3. [EstratÃ©gias de Deploy](#estratÃ©gias-de-deploy)
4. [ConfiguraÃ§Ã£o do Frontend](#configuraÃ§Ã£o-do-frontend)
5. [ConfiguraÃ§Ã£o do Backend](#configuraÃ§Ã£o-do-backend)
   - [OpÃ§Ã£o AWS (Recomendado se vocÃª tem AWS)](#-opÃ§Ã£o-aws-backend-na-aws-recomendado-se-vocÃª-tem-aws)
   - [EstratÃ©gia 1: AWS App Runner](#estratÃ©gia-1-aws-app-runner-mais-simples---comece-aqui)
   - [EstratÃ©gia 2: EC2](#estratÃ©gia-2-ec2-recomendado-para-produÃ§Ã£o)
   - [EstratÃ©gia 3: ECS Fargate](#estratÃ©gia-3-ecs-fargate-para-escalar)
   - [Outras OpÃ§Ãµes](#opÃ§Ã£o-a-backend-em-railway-alternativa-se-nÃ£o-usar-aws)
6. [Deploy Passo a Passo](#deploy-passo-a-passo)
7. [Alternativas Recomendadas](#alternativas-recomendadas)

---

## ðŸ“Š AnÃ¡lise do Projeto

### Estrutura Atual

```
booksmd/
â”œâ”€â”€ backend/          # FastAPI (Python)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/      # Rotas REST
â”‚   â”‚   â”œâ”€â”€ analyzer/ # AnÃ¡lise com LLM
â”‚   â”‚   â”œâ”€â”€ extractors/ # ExtraÃ§Ã£o de PDF/EPUB/TXT
â”‚   â”‚   â”œâ”€â”€ generator/ # GeraÃ§Ã£o MD/PDF
â”‚   â”‚   â””â”€â”€ storage/  # Armazenamento local (JSON)
â”‚   â”œâ”€â”€ main.py       # Servidor FastAPI
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend/         # Angular 18
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ app/
    â”‚   â”‚   â”œâ”€â”€ pages/
    â”‚   â”‚   â””â”€â”€ services/ # ApiService
    â”‚   â””â”€â”€ environments/
    â””â”€â”€ package.json
```

### CaracterÃ­sticas do Backend

- **Framework**: FastAPI (Python)
- **Processamento**: AnÃ¡lise longa de livros (pode levar minutos)
- **Armazenamento**: Sistema de arquivos local (`uploads/`, `outputs/`, `data/jobs.json`)
- **DependÃªncias Pesadas**: 
  - PyMuPDF (PDF)
  - WeasyPrint (PDF generation)
  - MÃºltiplos providers de LLM (OpenAI, Ollama, Hugging Face, Bedrock, Gradio)
- **Uploads**: AtÃ© 10GB de arquivos
- **CORS**: ConfigurÃ¡vel via variÃ¡veis de ambiente

### CaracterÃ­sticas do Frontend

- **Framework**: Angular 18 (Standalone Components)
- **Build**: `ng build` â†’ `dist/booksmd/`
- **API URL**: Configurada via `environment.ts`
  - Desenvolvimento: `http://localhost:8000`
  - ProduÃ§Ã£o: `''` (same origin)

---

## âš ï¸ LimitaÃ§Ãµes e Desafios

### LimitaÃ§Ãµes da Vercel para Backend Python

1. **Timeout de FunÃ§Ãµes Serverless**
   - **Hobby (Free)**: 10 segundos mÃ¡ximo
   - **Pro**: 60 segundos mÃ¡ximo
   - **Problema**: AnÃ¡lise de livros pode levar vÃ¡rios minutos

2. **Limite de Upload**
   - **Hobby**: 50MB por requisiÃ§Ã£o
   - **Pro**: 4.5GB por requisiÃ§Ã£o
   - **Problema**: Livros podem ser grandes

3. **Armazenamento Persistente**
   - Vercel nÃ£o oferece armazenamento de arquivos persistente
   - Arquivos sÃ£o perdidos entre execuÃ§Ãµes
   - **Problema**: Precisa de `uploads/`, `outputs/`, `data/jobs.json`

4. **DependÃªncias Pesadas**
   - WeasyPrint requer bibliotecas do sistema (GTK, Cairo, etc.)
   - PyMuPDF pode ter problemas em ambiente serverless
   - **Problema**: Build pode falhar ou ser muito lento

5. **Processamento Longo**
   - Serverless nÃ£o Ã© adequado para tarefas longas
   - **Problema**: AnÃ¡lise de livros Ã© uma tarefa longa

### O que Funciona Bem na Vercel

âœ… **Frontend Angular** - Perfeito para Vercel
- Build estÃ¡tico otimizado
- CDN global
- Deploy rÃ¡pido

---

## ðŸŽ¯ EstratÃ©gias de Deploy

### OpÃ§Ã£o 1: Frontend na Vercel + Backend Separado (RECOMENDADO)

**Arquitetura:**
```
Frontend (Vercel) â†’ Backend (Railway/Render/Fly.io/AWS)
```

**Vantagens:**
- âœ… Frontend otimizado na Vercel
- âœ… Backend com processamento longo
- âœ… Armazenamento persistente
- âœ… Sem limitaÃ§Ãµes de timeout

**Desvantagens:**
- âš ï¸ Precisa configurar CORS no backend
- âš ï¸ Dois serviÃ§os para gerenciar

### OpÃ§Ã£o 2: Tudo na Vercel (NÃƒO RECOMENDADO)

**Arquitetura:**
```
Frontend (Vercel) â†’ API Routes (Vercel Serverless)
```

**Problemas:**
- âŒ Timeout de 10-60s insuficiente
- âŒ Sem armazenamento persistente
- âŒ DependÃªncias pesadas problemÃ¡ticas
- âŒ Uploads grandes limitados

### OpÃ§Ã£o 3: Backend como Serverless Functions (PARCIAL)

**Arquitetura:**
```
Frontend (Vercel) â†’ API Routes (Vercel) â†’ External Storage (S3/Cloudflare R2)
```

**Funciona para:**
- âœ… Endpoints simples (status, download)
- âœ… Proxy para backend externo

**NÃ£o funciona para:**
- âŒ Processamento longo (anÃ¡lise)
- âŒ Upload direto de arquivos grandes

---

## âš™ï¸ ConfiguraÃ§Ã£o do Frontend

### 1. Arquivo `vercel.json` na Raiz

Crie um arquivo `vercel.json` na raiz do projeto:

```json
{
  "buildCommand": "cd frontend && npm install && npm run build",
  "outputDirectory": "frontend/dist/booksmd",
  "framework": "angular",
  "rewrites": [
    {
      "source": "/(.*)",
      "destination": "/index.html"
    }
  ],
  "headers": [
    {
      "source": "/assets/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "public, max-age=31536000, immutable"
        }
      ]
    }
  ]
}
```

### 2. Atualizar `environment.prod.ts`

O arquivo jÃ¡ estÃ¡ configurado para usar same origin:

```typescript
export const environment = {
  production: true,
  apiUrl: '' // Same origin in production
};
```

**IMPORTANTE**: Se o backend estiver em outro domÃ­nio, vocÃª precisa atualizar a URL.

#### OpÃ§Ã£o A: Usar o script automatizado (Recomendado)

```bash
cd frontend
npm run set-api-url https://seu-backend.railway.app
```

Ou diretamente:

```bash
cd frontend
node replace-api-url.js https://seu-backend.railway.app
```

#### OpÃ§Ã£o B: Editar manualmente

Edite `frontend/src/environments/environment.prod.ts`:

```typescript
export const environment = {
  production: true,
  apiUrl: 'https://seu-backend.railway.app' // URL do backend
};
```

### 3. Configurar VariÃ¡veis de Ambiente na Vercel

No painel da Vercel, adicione:

```
NODE_ENV=production
```

Se usar backend externo:
```
VITE_API_URL=https://seu-backend.railway.app
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do Backend

### ðŸ† OpÃ§Ã£o AWS: Backend na AWS (RECOMENDADO se vocÃª tem AWS)

Como vocÃª jÃ¡ tem AWS e AWS CLI, esta Ã© a melhor opÃ§Ã£o! Vou detalhar as 3 melhores estratÃ©gias:

#### EstratÃ©gia 1: AWS App Runner (MAIS SIMPLES - Comece aqui!)

**Por que escolher:**
- âœ… Mais fÃ¡cil de configurar
- âœ… Deploy automÃ¡tico via GitHub
- âœ… Escala automaticamente
- âœ… HTTPS automÃ¡tico
- âœ… Custo baixo (~$5-20/mÃªs)

**Passo a Passo:**

1. **Criar Dockerfile no `backend/`:**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instala dependÃªncias do sistema para WeasyPrint
RUN apt-get update && apt-get install -y \
    libpango-1.0-0 \
    libharfbuzz0b \
    libpangoft2-1.0-0 \
    libcairo2 \
    libgdk-pixbuf2.0-0 \
    libffi-dev \
    shared-mime-info \
    && rm -rf /var/lib/apt/lists/*

# Copia requirements e instala dependÃªncias Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copia cÃ³digo
COPY . .

# ExpÃµe porta (App Runner usa PORT automÃ¡tico)
EXPOSE 8000

# Comando de start
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

2. **Criar `apprunner.yaml` na raiz do projeto (opcional):**

```yaml
version: 1.0
runtime: docker
build:
  commands:
    build:
      - echo "Building BooksMD Backend"
run:
  runtime-version: latest
  command: uvicorn main:app --host 0.0.0.0 --port 8000
  network:
    port: 8000
    env: PORT
  env:
    - name: LLM_PROVIDER
      value: "gradio"
    - name: CORS_ORIGINS
      value: "https://seu-frontend.vercel.app"
```

3. **Deploy via Console AWS:**

   a. Acesse [AWS App Runner Console](https://console.aws.amazon.com/apprunner)
   
   b. Clique em "Create service"
   
   c. Escolha "Source code repository" â†’ Conecte GitHub
   
   d. Selecione seu repositÃ³rio e branch
   
   e. Configure:
      - **Build settings**: 
        - Build command: `cd backend && docker build -t booksmd-backend .`
        - Start command: (deixar vazio, usa Dockerfile)
      - **Service settings**:
        - Service name: `booksmd-backend`
        - Port: `8000`
        - Environment variables:
          ```
          LLM_PROVIDER=gradio
          GRADIO_SPACE_ID=burak/Llama-4-Maverick-17B-Websearch
          CORS_ORIGINS=https://seu-frontend.vercel.app
          HOST=0.0.0.0
          PORT=8000
          DEBUG=False
          ```
   
   f. Clique em "Create & deploy"
   
   g. Aguarde ~5-10 minutos para build e deploy
   
   h. Anote a URL gerada (ex: `https://xxxxx.us-east-1.awsapprunner.com`)

4. **Configurar S3 para Storage (IMPORTANTE):**

Como App Runner nÃ£o tem storage persistente, vocÃª precisa usar S3:

```bash
# Criar bucket S3
aws s3 mb s3://booksmd-uploads --region us-east-1
aws s3 mb s3://booksmd-outputs --region us-east-1

# Configurar CORS no bucket
aws s3api put-bucket-cors --bucket booksmd-uploads --cors-configuration file://cors.json
```

Crie `cors.json`:
```json
{
  "CORSRules": [
    {
      "AllowedOrigins": ["*"],
      "AllowedMethods": ["GET", "PUT", "POST", "DELETE"],
      "AllowedHeaders": ["*"],
      "MaxAgeSeconds": 3000
    }
  ]
}
```

5. **Atualizar cÃ³digo para usar S3 (opcional, mas recomendado):**

VocÃª precisaria modificar o cÃ³digo para salvar arquivos no S3 ao invÃ©s do sistema de arquivos local. Isso Ã© mais complexo, entÃ£o para comeÃ§ar, vocÃª pode usar a EstratÃ©gia 2 (EC2) que tem storage persistente.

**Custo:** ~$5-20/mÃªs

---

#### EstratÃ©gia 2: EC2 (RECOMENDADO para produÃ§Ã£o)

**Por que escolher:**
- âœ… Storage persistente (EBS)
- âœ… Sem limite de tempo
- âœ… Controle total
- âœ… Pode usar Spot Instances (mais barato)
- âœ… Melhor para processamento longo

**Passo a Passo:**

1. **Criar instÃ¢ncia EC2:**

```bash
# Via AWS CLI
aws ec2 run-instances \
  --image-id ami-0c55b159cbfafe1f0 \
  --instance-type t3.medium \
  --key-name sua-chave \
  --security-group-ids sg-xxxxx \
  --subnet-id subnet-xxxxx \
  --user-data file://user-data.sh \
  --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=booksmd-backend}]'
```

2. **Criar `user-data.sh` (script de inicializaÃ§Ã£o):**

```bash
#!/bin/bash
yum update -y
yum install -y python3.11 python3-pip git

# Instala dependÃªncias do sistema para WeasyPrint
yum install -y \
  cairo-devel \
  pango-devel \
  libffi-devel \
  shared-mime-info

# Clona repositÃ³rio (ou usa CodeDeploy)
cd /opt
git clone https://github.com/seu-usuario/booksmd.git
cd booksmd/backend

# Cria ambiente virtual
python3.11 -m venv venv
source venv/bin/activate

# Instala dependÃªncias
pip install -r requirements.txt

# Cria diretÃ³rios
mkdir -p uploads outputs data

# Cria arquivo .env
cat > .env << EOF
LLM_PROVIDER=gradio
GRADIO_SPACE_ID=burak/Llama-4-Maverick-17B-Websearch
CORS_ORIGINS=https://seu-frontend.vercel.app
HOST=0.0.0.0
PORT=8000
DEBUG=False
UPLOAD_DIR=/opt/booksmd/backend/uploads
OUTPUT_DIR=/opt/booksmd/backend/outputs
EOF

# Cria service systemd
cat > /etc/systemd/system/booksmd.service << EOF
[Unit]
Description=BooksMD Backend
After=network.target

[Service]
Type=simple
User=ec2-user
WorkingDirectory=/opt/booksmd/backend
Environment="PATH=/opt/booksmd/backend/venv/bin"
ExecStart=/opt/booksmd/backend/venv/bin/python main.py
Restart=always

[Install]
WantedBy=multi-user.target
EOF

# Inicia serviÃ§o
systemctl daemon-reload
systemctl enable booksmd
systemctl start booksmd
```

3. **Configurar Security Group:**

```bash
# Permite HTTP/HTTPS
aws ec2 authorize-security-group-ingress \
  --group-id sg-xxxxx \
  --protocol tcp \
  --port 8000 \
  --cidr 0.0.0.0/0
```

4. **Configurar Application Load Balancer (para HTTPS):**

```bash
# Criar ALB
aws elbv2 create-load-balancer \
  --name booksmd-alb \
  --subnets subnet-xxxxx subnet-yyyyy \
  --security-groups sg-xxxxx

# Criar target group
aws elbv2 create-target-group \
  --name booksmd-targets \
  --protocol HTTP \
  --port 8000 \
  --vpc-id vpc-xxxxx

# Registrar instÃ¢ncia
aws elbv2 register-targets \
  --target-group-arn arn:aws:elasticloadbalancing:... \
  --targets Id=i-xxxxx

# Criar listener HTTPS (com certificado ACM)
aws elbv2 create-listener \
  --load-balancer-arn arn:aws:elasticloadbalancing:... \
  --protocol HTTPS \
  --port 443 \
  --certificates CertificateArn=arn:aws:acm:... \
  --default-actions Type=forward,TargetGroupArn=arn:aws:elasticloadbalancing:...
```

5. **Anexar EBS Volume para Storage Persistente:**

```bash
# Criar volume EBS (100GB)
aws ec2 create-volume \
  --size 100 \
  --volume-type gp3 \
  --availability-zone us-east-1a

# Anexar Ã  instÃ¢ncia
aws ec2 attach-volume \
  --volume-id vol-xxxxx \
  --instance-id i-xxxxx \
  --device /dev/sdf

# Na instÃ¢ncia, formatar e montar:
# sudo mkfs -t ext4 /dev/xvdf
# sudo mkdir /data
# sudo mount /dev/xvdf /data
# echo '/dev/xvdf /data ext4 defaults,nofail 0 2' | sudo tee -a /etc/fstab
```

**Custo:** ~$30-100/mÃªs (dependendo da instÃ¢ncia)

---

#### EstratÃ©gia 3: ECS Fargate (Para escalar)

**Por que escolher:**
- âœ… Escala automaticamente
- âœ… Containers isolados
- âœ… IntegraÃ§Ã£o com outros serviÃ§os AWS

**Passo a Passo:**

1. **Criar Dockerfile** (mesmo da EstratÃ©gia 1)

2. **Criar `Dockerfile` e fazer push para ECR:**

```bash
# Login no ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com

# Criar repositÃ³rio
aws ecr create-repository --repository-name booksmd-backend

# Build e push
cd backend
docker build -t booksmd-backend .
docker tag booksmd-backend:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/booksmd-backend:latest
docker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/booksmd-backend:latest
```

3. **Criar task definition:**

```json
{
  "family": "booksmd-backend",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "1024",
  "memory": "2048",
  "containerDefinitions": [
    {
      "name": "booksmd-backend",
      "image": "123456789012.dkr.ecr.us-east-1.amazonaws.com/booksmd-backend:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {"name": "LLM_PROVIDER", "value": "gradio"},
        {"name": "CORS_ORIGINS", "value": "https://seu-frontend.vercel.app"},
        {"name": "HOST", "value": "0.0.0.0"},
        {"name": "PORT", "value": "8000"}
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/booksmd-backend",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

4. **Criar cluster e serviÃ§o via Console AWS ou CLI**

**Custo:** ~$50-200/mÃªs

---

### ðŸŽ¯ RecomendaÃ§Ã£o Final para AWS

**Para comeÃ§ar rÃ¡pido:** Use **App Runner** (EstratÃ©gia 1)
- Mais simples
- Deploy em ~10 minutos
- Custo baixo

**Para produÃ§Ã£o:** Use **EC2** (EstratÃ©gia 2)
- Storage persistente
- Controle total
- Melhor custo-benefÃ­cio

**Para escalar:** Use **ECS Fargate** (EstratÃ©gia 3)
- Escala automÃ¡tica
- Melhor para alto volume

---

### OpÃ§Ã£o A: Backend em Railway (Alternativa se nÃ£o usar AWS)

#### 1. Criar `railway.json` (opcional)

```json
{
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "cd backend && python main.py",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

#### 2. Criar `Procfile` no diretÃ³rio `backend/`

```
web: cd backend && python main.py
```

Ou:

```
web: uvicorn main:app --host 0.0.0.0 --port $PORT
```

#### 3. VariÃ¡veis de Ambiente no Railway

Configure no painel do Railway:

```env
LLM_PROVIDER=gradio
GRADIO_SPACE_ID=burak/Llama-4-Maverick-17B-Websearch
GRADIO_USE_WEB_SEARCH=False

# Ou se usar OpenAI:
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o

HOST=0.0.0.0
PORT=$PORT
DEBUG=False

CORS_ORIGINS=https://seu-frontend.vercel.app,https://seu-frontend.vercel.app/*
```

#### 4. Armazenamento Persistente

Railway oferece volume persistente. Configure:

```env
UPLOAD_DIR=/data/uploads
OUTPUT_DIR=/data/outputs
```

E monte um volume em `/data` no Railway.

### OpÃ§Ã£o B: Backend em Render

#### 1. Criar `render.yaml` na raiz

```yaml
services:
  - type: web
    name: booksmd-backend
    env: python
    buildCommand: cd backend && pip install -r requirements.txt
    startCommand: cd backend && python main.py
    envVars:
      - key: LLM_PROVIDER
        value: gradio
      - key: CORS_ORIGINS
        value: https://seu-frontend.vercel.app
      - key: HOST
        value: 0.0.0.0
      - key: PORT
        value: 10000
```

### OpÃ§Ã£o C: Backend em Fly.io

#### 1. Criar `fly.toml` no diretÃ³rio `backend/`

```toml
app = "booksmd-backend"
primary_region = "gru"

[build]

[env]
  LLM_PROVIDER = "gradio"
  HOST = "0.0.0.0"
  PORT = "8080"

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 2048
```

#### 2. Criar `Dockerfile` no diretÃ³rio `backend/`

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instala dependÃªncias do sistema para WeasyPrint
RUN apt-get update && apt-get install -y \
    libpango-1.0-0 \
    libharfbuzz0b \
    libpangoft2-1.0-0 \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "main.py"]
```

---

## ðŸ“ Deploy Passo a Passo

### Passo 1: Preparar o RepositÃ³rio

```bash
# Certifique-se de que tudo estÃ¡ commitado
git add .
git commit -m "Preparar para deploy na Vercel"
git push origin main
```

### Passo 2: Deploy do Frontend na Vercel

1. Acesse [vercel.com](https://vercel.com)
2. FaÃ§a login com GitHub
3. Clique em "Add New Project"
4. Importe o repositÃ³rio `booksmd`
5. Configure:
   - **Framework Preset**: Angular
   - **Root Directory**: `frontend`
   - **Build Command**: `npm run build`
   - **Output Directory**: `dist/booksmd`
6. Adicione variÃ¡veis de ambiente (se necessÃ¡rio)
7. Clique em "Deploy"

### Passo 3: Deploy do Backend (Railway - Exemplo)

1. Acesse [railway.app](https://railway.app)
2. FaÃ§a login com GitHub
3. Clique em "New Project"
4. Selecione "Deploy from GitHub repo"
5. Escolha o repositÃ³rio `booksmd`
6. Configure:
   - **Root Directory**: `backend`
   - **Start Command**: `python main.py`
7. Adicione variÃ¡veis de ambiente
8. Configure volume persistente para `/data`
9. Anote a URL gerada (ex: `https://booksmd-backend.railway.app`)

### Passo 4: Atualizar Frontend com URL do Backend

1. Anote a URL do backend (ex: `https://booksmd-backend.railway.app`)
2. Atualize o `environment.prod.ts` usando o script:

```bash
cd frontend
npm run set-api-url https://seu-backend.railway.app
```

Ou edite manualmente `frontend/src/environments/environment.prod.ts`:

```typescript
export const environment = {
  production: true,
  apiUrl: 'https://seu-backend.railway.app'
};
```

3. Commit e push das alteraÃ§Ãµes:

```bash
git add frontend/src/environments/environment.prod.ts
git commit -m "Configurar URL do backend para produÃ§Ã£o"
git push origin main
```

4. O Vercel farÃ¡ redeploy automaticamente

### Passo 5: Configurar CORS no Backend

No Railway (ou outro serviÃ§o), adicione:

```env
CORS_ORIGINS=https://seu-frontend.vercel.app,https://seu-frontend.vercel.app/*
```

### Passo 6: Testar

1. Acesse o frontend: `https://seu-frontend.vercel.app`
2. Tente fazer upload de um livro
3. Verifique se o backend responde
4. Verifique logs no Railway/Vercel

---

## ðŸ”„ Alternativas Recomendadas

### Se Vercel NÃ£o For Adequado

#### OpÃ§Ã£o 1: Render (Full Stack)

- âœ… Suporta Python e Node.js
- âœ… Armazenamento persistente
- âœ… Sem timeout rÃ­gido
- âœ… Free tier disponÃ­vel

**Deploy:**
1. Crie `render.yaml` na raiz
2. Configure frontend e backend como serviÃ§os separados
3. Deploy automÃ¡tico via GitHub

#### OpÃ§Ã£o 2: Fly.io (Full Stack)

- âœ… Suporta Docker
- âœ… MÃ¡quinas persistentes
- âœ… Sem timeout
- âœ… Bom para processamento longo

**Deploy:**
1. Crie `Dockerfile` para backend
2. Crie `fly.toml` para cada serviÃ§o
3. Deploy via CLI: `fly deploy`

#### OpÃ§Ã£o 3: Railway (Full Stack)

- âœ… Simples de configurar
- âœ… Volumes persistentes
- âœ… Deploy automÃ¡tico
- âœ… Free tier limitado

**Deploy:**
1. Conecte repositÃ³rio GitHub
2. Configure variÃ¡veis de ambiente
3. Deploy automÃ¡tico

#### OpÃ§Ã£o 4: AWS (RECOMENDADO se vocÃª jÃ¡ tem AWS)

Como vocÃª jÃ¡ tem AWS e AWS CLI, esta Ã© uma excelente opÃ§Ã£o! Aqui estÃ£o as melhores estratÃ©gias:

##### ðŸ¥‡ OpÃ§Ã£o A: AWS App Runner (MAIS SIMPLES - Recomendado para comeÃ§ar)

**Vantagens:**
- âœ… Muito simples de configurar
- âœ… Deploy automÃ¡tico via GitHub
- âœ… Escala automaticamente
- âœ… Timeout de atÃ© 15 minutos (suficiente para a maioria dos casos)
- âœ… Custo baixo (paga apenas pelo uso)
- âœ… HTTPS automÃ¡tico

**LimitaÃ§Ãµes:**
- âš ï¸ Storage temporÃ¡rio (arquivos sÃ£o perdidos ao reiniciar)
- âš ï¸ SoluÃ§Ã£o: Usar S3 para uploads e outputs

**Deploy:**
1. Crie um `Dockerfile` no diretÃ³rio `backend/`
2. Configure App Runner no console AWS
3. Conecte com GitHub
4. Configure variÃ¡veis de ambiente
5. Use S3 para armazenar arquivos

**Custo estimado:** ~$5-20/mÃªs (dependendo do uso)

##### ðŸ¥ˆ OpÃ§Ã£o B: EC2 (MAIS CONTROLE - Recomendado para produÃ§Ã£o)

**Vantagens:**
- âœ… Controle total sobre a mÃ¡quina
- âœ… Storage persistente (EBS volumes)
- âœ… Sem limite de tempo de processamento
- âœ… Pode usar Spot Instances para economizar
- âœ… Pode instalar dependÃªncias do sistema (WeasyPrint)

**Desvantagens:**
- âš ï¸ Precisa gerenciar servidor (atualizaÃ§Ãµes, seguranÃ§a)
- âš ï¸ Mais complexo de configurar

**Deploy:**
1. Crie instÃ¢ncia EC2 (t3.medium ou maior)
2. Configure security groups
3. Instale Python, dependÃªncias
4. Configure systemd para auto-start
5. Use Application Load Balancer para HTTPS

**Custo estimado:** ~$30-100/mÃªs (dependendo da instÃ¢ncia)

##### ðŸ¥‰ OpÃ§Ã£o C: ECS/Fargate (ESCALÃVEL - Para alto volume)

**Vantagens:**
- âœ… Escala automaticamente
- âœ… Containers isolados
- âœ… IntegraÃ§Ã£o com outros serviÃ§os AWS
- âœ… Pode usar EFS para storage compartilhado

**Desvantagens:**
- âš ï¸ Mais complexo de configurar
- âš ï¸ Pode ser mais caro

**Custo estimado:** ~$50-200/mÃªs

##### ðŸ† OpÃ§Ã£o D: HÃ­brida (RECOMENDADA para produÃ§Ã£o)

**Arquitetura:**
```
Frontend (Vercel)
    â†“
Backend API (App Runner ou EC2)
    â†“
S3 (Uploads e Outputs)
    â†“
DynamoDB ou RDS (Jobs metadata)
```

**Vantagens:**
- âœ… Melhor custo-benefÃ­cio
- âœ… EscalÃ¡vel
- âœ… Storage persistente (S3)
- âœ… Frontend otimizado na Vercel

**Custo estimado:** ~$10-50/mÃªs

---

## ðŸ“‹ Checklist de Deploy

### Frontend (Vercel)
- [ ] Criar `vercel.json` na raiz
- [ ] Configurar `environment.prod.ts` com URL do backend
- [ ] Testar build local: `cd frontend && npm run build`
- [ ] Verificar que `dist/booksmd` contÃ©m os arquivos
- [ ] Configurar variÃ¡veis de ambiente na Vercel
- [ ] Deploy e testar acesso

### Backend (Railway/Render/Fly.io)
- [ ] Criar `Procfile` ou `Dockerfile`
- [ ] Configurar variÃ¡veis de ambiente
- [ ] Configurar CORS com URL do frontend
- [ ] Configurar volume persistente (se necessÃ¡rio)
- [ ] Testar endpoint `/health`
- [ ] Verificar logs de erro

### IntegraÃ§Ã£o
- [ ] Frontend consegue acessar backend (CORS OK)
- [ ] Upload de arquivo funciona
- [ ] Status de job Ã© atualizado
- [ ] Download de MD/PDF funciona
- [ ] Erros sÃ£o tratados corretamente

---

## ðŸ› Troubleshooting

### Erro: CORS bloqueado

**SoluÃ§Ã£o:**
- Verifique `CORS_ORIGINS` no backend
- Inclua a URL exata do frontend (com `https://`)
- Reinicie o backend apÃ³s mudar CORS

### Erro: Timeout na Vercel

**SoluÃ§Ã£o:**
- Backend nÃ£o pode estar na Vercel
- Use Railway/Render/Fly.io para backend
- Frontend na Vercel, backend externo

### Erro: Arquivos nÃ£o persistem

**SoluÃ§Ã£o:**
- Configure volume persistente no Railway
- Ou use S3/Cloudflare R2 para storage
- Atualize cÃ³digo para usar storage externo

### Erro: Build do frontend falha

**SoluÃ§Ã£o:**
- Verifique Node.js version (18+)
- Limpe cache: `rm -rf node_modules package-lock.json`
- Reinstale: `npm install`
- Verifique `angular.json` e `package.json`

### Erro: Backend nÃ£o inicia

**SoluÃ§Ã£o:**
- Verifique variÃ¡veis de ambiente
- Verifique `requirements.txt`
- Verifique logs no serviÃ§o de deploy
- Teste localmente primeiro

---

## ðŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Vercel](https://vercel.com/docs)
- [DocumentaÃ§Ã£o Railway](https://docs.railway.app)
- [DocumentaÃ§Ã£o Render](https://render.com/docs)
- [DocumentaÃ§Ã£o Fly.io](https://fly.io/docs)
- [Angular Deployment](https://angular.io/guide/deployment)

---

## ðŸ’¡ ConclusÃ£o

**RecomendaÃ§Ã£o Final:**

### ðŸ† Se vocÃª tem AWS (RECOMENDADO):

1. **Frontend**: Deploy na Vercel (otimizado, rÃ¡pido, CDN global)
2. **Backend**: Deploy na AWS
   - **Para comeÃ§ar rÃ¡pido**: AWS App Runner (~$5-20/mÃªs)
   - **Para produÃ§Ã£o**: EC2 com EBS (~$30-100/mÃªs)
   - **Para escalar**: ECS Fargate (~$50-200/mÃªs)
3. **Storage**: EBS volumes (EC2) ou S3 (App Runner/ECS)
4. **ConfiguraÃ§Ã£o**: CORS adequado, variÃ¡veis de ambiente configuradas
5. **Monitoramento**: CloudWatch Logs

**Vantagens da AWS:**
- âœ… VocÃª jÃ¡ tem acesso
- âœ… Controle total sobre recursos
- âœ… EscalÃ¡vel e confiÃ¡vel
- âœ… IntegraÃ§Ã£o com outros serviÃ§os AWS
- âœ… Custo competitivo

### Alternativa (se nÃ£o usar AWS):

1. **Frontend**: Deploy na Vercel
2. **Backend**: Deploy em Railway ou Render
3. **ConfiguraÃ§Ã£o**: CORS adequado, variÃ¡veis de ambiente configuradas

Esta arquitetura oferece o melhor dos dois mundos: frontend rÃ¡pido na Vercel e backend robusto em um serviÃ§o adequado para processamento longo.

---

**Ãšltima atualizaÃ§Ã£o**: 2024
**VersÃ£o do projeto**: 1.0.0

